{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from rbm import RBM\n",
    "from autoencoder_rbm import Autoencoder_RBM\n",
    "from dbn import DeepBeliefNetwork\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "The shape of the dataset for training:  (55000, 784) (55000, 10)\n",
      "The shape of the dataset for validation:  (5000, 784) (5000, 10)\n",
      "The shape of the dataset for test:  (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Download the data in the working directory\n",
    "mnist = input_data.read_data_sets(\"../data/mnist/\", one_hot=True)\n",
    "\n",
    "#training_data = {image: mnist.train.images, label: mnist.train.labels}\n",
    "#validation_data = {image: mnist.validation.images, label: mnist.validation.labels}\n",
    "#test_data = {image: mnist.test.images, label: mnist.test.labels}\n",
    "train_dataset = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "validation_dataset = mnist.validation.images\n",
    "validation_labels = mnist.validation.labels\n",
    "test_dataset = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "print(\"The shape of the dataset for training: \", train_dataset.shape, train_labels.shape)\n",
    "print(\"The shape of the dataset for validation: \", validation_dataset.shape, validation_labels.shape)\n",
    "print(\"The shape of the dataset for test: \", test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 4 6 1 8 1 0 9 8 0 3 1 2 7 0 2 9 6 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(train_labels[:21], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.DataFrame(train_dataset)\n",
    "labels_tmp = pd.DataFrame(train_labels[:10])\n",
    "train_set.loc[:10, :10].loc[np.argmax(train_labels[:10],axis=1)==1,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6179, 784)\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   774  775  776  777  \\\n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    778  779  780  781  782  783  \n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "23  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_1 = train_set.loc[np.argmax(train_labels, axis=1)==1, :]\n",
    "train_labels_1 = train_labels[list(train_set_1.index.values)]\n",
    "print(train_set_1.shape)\n",
    "print(train_labels_1[:10])\n",
    "train_set_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5715, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...   774  775  776  777  \\\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "35  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    778  779  780  781  782  783  \n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "14  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "35  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_7 = train_set.loc[np.argmax(train_labels, axis=1)==7, :]\n",
    "print(train_set_7.shape)\n",
    "train_set_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Mix 1 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 784)\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Choose 20 images of 7\n",
    "num_abonormal = 20\n",
    "batch_images_7 = train_set_7.sample(num_abonormal)\n",
    "batch_labels_7 = train_labels[list(batch_images_7.index.values)]\n",
    "print(batch_images_7.shape)\n",
    "print(batch_labels_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_mix = pd.concat([train_set_1, batch_images_7], ignore_index=True, axis=0)\n",
    "train_labels_mix = pd.concat([pd.DataFrame(train_labels_1), pd.DataFrame(batch_labels_7)], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1    2    3    4    5    6    7    8    9\n",
      "6194  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "6195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "6196  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "6197  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "6198  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print(train_labels_mix.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6199, 794)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle train_set_mix and train_labels_mix in the same way\n",
    "train_set_mix_total = pd.concat([train_set_mix, train_labels_mix], axis=1)\n",
    "train_set_mix_total = train_set_mix_total.sample(frac=1).reset_index(drop=True)\n",
    "print(train_set_mix_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6199, 784)\n",
      "(6199, 10)\n"
     ]
    }
   ],
   "source": [
    "train_set_shuffle = train_set_mix_total.iloc[:, 0:batch_images_7.shape[1]]\n",
    "train_labels_shuffle = train_set_mix_total.iloc[:, batch_images_7.shape[1]:]\n",
    "print(train_set_shuffle.shape)\n",
    "print(train_labels_shuffle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9\n",
       "582   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "980   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1224  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1446  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1539  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1703  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "1791  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "2000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "2638  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "2678  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "2843  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "3001  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "4789  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "4811  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "4832  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5340  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5399  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5677  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5930  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "5932  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_abnormal = train_labels_shuffle.index[np.argmax(np.array(train_labels_shuffle), axis=1)==7]\n",
    "train_labels_shuffle[np.argmax(np.array(train_labels_shuffle), axis=1)==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxgFpItxoNBoH5P8DisXP/DEv95EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d1ec0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_set_shuffle.iloc[44, :].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recons_error(input_set, recons):\n",
    "    dif = input_set - recons\n",
    "    dif = np.power(dif, 2)\n",
    "    return np.mean(dif, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: Training set: current loss 0.168695  ||  Validation set: current loss 0.168681\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 2227 5340  582 2638 5930 3700\n",
      " 2830  212  498  980 1791  404  911 1805 3226 3083]\n",
      "Iter 2: Training set: current loss 0.168639  ||  Validation set: current loss 0.168631\n",
      "Validation:  [1539 1894 1317 3001 5677 1580  628 3016 2843 2227 5340 2638 3700  582 5930\n",
      "  212 2830  498 1791  980  911 1805  404 3226 3083]\n",
      "Iter 3: Training set: current loss 0.168718  ||  Validation set: current loss 0.168690\n",
      "Validation:  [1539 1894 3001 5677 1317 1580  628 3016 2843 2227 2638 5340  582 5930 3700\n",
      "  498 2830  212  980 1791  404 3226  911 1805 5896]\n",
      "Iter 4: Training set: current loss 0.168662  ||  Validation set: current loss 0.168662\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 2227 5340 2638  582 5930 3700\n",
      "  498 2830  212  980 1791  404 3226  911 1805 5896]\n",
      "Iter 5: Training set: current loss 0.168531  ||  Validation set: current loss 0.168559\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 2227 5340 2638  582 3700 5930\n",
      "  498 2830  212  980 1791  911  404 1805 3226 5896]\n",
      "Iter 6: Training set: current loss 0.168569  ||  Validation set: current loss 0.168550\n",
      "Validation:  [1539 1894 3001 5677 1317 1580  628 3016 2843 2227 5340 2638  582 5930 3700\n",
      "  498 2830  212 1791  980  404 3226  911 1805 5896]\n",
      "Iter 7: Training set: current loss 0.168542  ||  Validation set: current loss 0.168540\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 2227 5340 3700 2638  582 5930\n",
      "  498  212 2830  980 1791  911  404 1805 3226 5896]\n",
      "Iter 8: Training set: current loss 0.168582  ||  Validation set: current loss 0.168593\n",
      "Validation:  [1539 1894 3001 1317 5677 1580  628 3016 2843 2227 5340 2638  582 5930 3700\n",
      "  498 2830 1791  212  980  404 3226  911 1805 5896]\n",
      "Iter 9: Training set: current loss 0.168461  ||  Validation set: current loss 0.168467\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 5340 2227 2638  582 5930 3700\n",
      "  212  498 1791 2830  980  404  911 1805 3226 3083]\n",
      "Iter 10: Training set: current loss 0.168453  ||  Validation set: current loss 0.168458\n",
      "Validation:  [1539 1894 3001 1317 5677 1580  628 3016 2843 2227 5340 2638  582 5930 3700\n",
      "  498 2830  212  980 1791  404 3226  911 1805 5896]\n",
      "Iter 11: Training set: current loss 0.168493  ||  Validation set: current loss 0.168472\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 5340 2227 3700  582 2638 5930\n",
      "  212  980  911 1791 1805 2830  498 3083  404 3226]\n",
      "Iter 12: Training set: current loss 0.168371  ||  Validation set: current loss 0.168364\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 2227 5340 2638 3700  582 5930\n",
      "  212  498 2830  980 1791  911  404 1805 3226 3083]\n",
      "Iter 13: Training set: current loss 0.168411  ||  Validation set: current loss 0.168380\n",
      "Validation:  [1539 1894 1317 3001 5677 1580  628 3016 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830  498  980 1791  911  404 1805 3226 3083]\n",
      "Iter 14: Training set: current loss 0.168263  ||  Validation set: current loss 0.168272\n",
      "Validation:  [1539 1894 3001 5677 1317 1580  628 3016 2843 2227 2638 5340  582 5930 3700\n",
      " 2830  212  498  980 1791  911  404 1805 3226 3083]\n",
      "Iter 15: Training set: current loss 0.168238  ||  Validation set: current loss 0.168225\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830  980 1791  498  911  404 1805 3226 3083]\n",
      "Iter 16: Training set: current loss 0.168196  ||  Validation set: current loss 0.168188\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830  498  980 1791  911  404 1805 3226 3083]\n",
      "Iter 17: Training set: current loss 0.168202  ||  Validation set: current loss 0.168171\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      " 2830  980  212  498 1791  911  404 1805 3226 3083]\n",
      "Iter 18: Training set: current loss 0.168186  ||  Validation set: current loss 0.168175\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016  628 2843 2227 5340  582 2638 3700 5930\n",
      "  212  980 2830  911 1791 1805  498  404 3083 3226]\n",
      "Iter 19: Training set: current loss 0.168153  ||  Validation set: current loss 0.168155\n",
      "Validation:  [1539 1894 1317 5677 3001 1580  628 3016 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830  980  498 1791  911  404 1805 3226 3083]\n",
      "Iter 20: Training set: current loss 0.167980  ||  Validation set: current loss 0.168004\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 5340 2227 2638  582 3700 5930\n",
      "  212 1791 2830  980  498  911 1805  404 3226 3083]\n",
      "Iter 21: Training set: current loss 0.168025  ||  Validation set: current loss 0.167994\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016  628 2843 2227 2638 5340 3700  582 5930\n",
      "  212 2830  980  911 1791  498 1805  404 3226 3083]\n",
      "Iter 22: Training set: current loss 0.168042  ||  Validation set: current loss 0.168041\n",
      "Validation:  [1539 1894 1317 3001 5677  628 1580 3016 2843 5340 2227 2638  582 5930 3700\n",
      "  498 2830 1791  212  980  404 3226  911 1805 5896]\n",
      "Iter 23: Training set: current loss 0.167905  ||  Validation set: current loss 0.167888\n",
      "Validation:  [1539 1894 3001 5677 1317 1580  628 3016 2843 2227 5340 2638  582 3700 5930\n",
      "  212  498 2830 1791  980  404  911 3226 1805 5896]\n",
      "Iter 24: Training set: current loss 0.167814  ||  Validation set: current loss 0.167795\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 5340 2227 2638  582 3700 5930\n",
      "  212 2830 1791  980  498  911 1805  404 3226 3083]\n",
      "Iter 25: Training set: current loss 0.167934  ||  Validation set: current loss 0.167920\n",
      "Validation:  [1539 1894 3001 5677 1580 1317  628 3016 2843 2227 5340 2638  582 5930 3700\n",
      "  498 2830  212  980 1791  404 3226  911 1805 5896]\n",
      "Iter 26: Training set: current loss 0.167791  ||  Validation set: current loss 0.167777\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 5340 2227 2638 3700  582 5930\n",
      "  212 2830  980 1791  911 1805  498  404 3083 3226]\n",
      "Iter 27: Training set: current loss 0.167652  ||  Validation set: current loss 0.167673\n",
      "Validation:  [1539 1894 1317 3001 5677 1580 3016  628 2843 2227 5340 2638  582 5930 3700\n",
      "  212  980 2830 1791  498  911  404 1805 3226 3083]\n",
      "Iter 28: Training set: current loss 0.167660  ||  Validation set: current loss 0.167652\n",
      "Validation:  [1539 1894 1317 3001 5677 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830  980 1791  911  498 1805  404 3226 3083]\n",
      "Iter 29: Training set: current loss 0.167496  ||  Validation set: current loss 0.167510\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016  628 2843 5340 2227 2638  582 3700 5930\n",
      "  212 1791 2830  980  911  498 1805  404 3226  451]\n",
      "Iter 30: Training set: current loss 0.167535  ||  Validation set: current loss 0.167545\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016  628 2843 5340 2227 2638  582 3700 5930\n",
      "  212  980 2830 1791  911  498 1805  404 3226 3083]\n",
      "Iter 31: Training set: current loss 0.167348  ||  Validation set: current loss 0.167356\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016 2843  628 5340 2227 2638  582 3700 5930\n",
      "  212 1791  980 2830  911 1805  498  404 3083 3226]\n",
      "Iter 32: Training set: current loss 0.167311  ||  Validation set: current loss 0.167324\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016 2843  628 5340 2638  582 2227 5930 3700\n",
      "  980 2830  212 1791  498 1805  911  404 3226 3083]\n",
      "Iter 33: Training set: current loss 0.167186  ||  Validation set: current loss 0.167162\n",
      "Validation:  [1539 1894 1317 3001 5677 1580 3016 2843  628 5340 2638 2227  582 3700 5930\n",
      "  212 2830 1791  980  911 1805  498  404 3083 3226]\n",
      "Iter 34: Training set: current loss 0.167108  ||  Validation set: current loss 0.167112\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016 2843  628 5340 2227 2638  582 5930 3700\n",
      " 1791  980  212 2830  498  911 1805  404 3226 3083]\n",
      "Iter 35: Training set: current loss 0.166994  ||  Validation set: current loss 0.166986\n",
      "Validation:  [1539 1894 1317 3001 5677 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830  980 1791  498  911 1805  404 3226 3083]\n",
      "Iter 36: Training set: current loss 0.167086  ||  Validation set: current loss 0.167103\n",
      "Validation:  [1539 1894 1317 5677 3001 3016 1580 2843  628 5340 2638  582 3700 5930 2227\n",
      "  212 1791  980  911 1805 2830 3083  498  404  451]\n",
      "Iter 37: Training set: current loss 0.166848  ||  Validation set: current loss 0.166863\n",
      "Validation:  [1539 1894 1317 3001 5677 1580  628 3016 2843 2227 5340 2638  582 3700 5930\n",
      " 2830  212 1791  498  980  404  911 1805 3226 5896]\n",
      "Iter 38: Training set: current loss 0.166712  ||  Validation set: current loss 0.166702\n",
      "Validation:  [1539 1894 5677 3001 1317 1580 3016 2843  628 5340 2227 2638  582 3700 5930\n",
      "  212 1791 2830  980  911 1805  498  404 3083 3226]\n",
      "Iter 39: Training set: current loss 0.166688  ||  Validation set: current loss 0.166670\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016  628 2843 2227 2638 5340 3700  582 5930\n",
      "  212 2830  980 1791  911  498 1805  404 3226  451]\n",
      "Iter 40: Training set: current loss 0.166485  ||  Validation set: current loss 0.166472\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      "  212 2830 1791  980  911  498 1805  404 3083 3226]\n",
      "Iter 41: Training set: current loss 0.166467  ||  Validation set: current loss 0.166470\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      "  980  212 1791 2830  911 1805  498  404 3083 3226]\n",
      "Iter 42: Training set: current loss 0.166283  ||  Validation set: current loss 0.166285\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016 2843  628 5340 2638  582 2227 3700 5930\n",
      " 1791  212  980 2830  911 1805  498  404 3083   78]\n",
      "Iter 43: Training set: current loss 0.166124  ||  Validation set: current loss 0.166129\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      "  980  212 2830 1791  911 1805  498  404 3083  451]\n",
      "Iter 44: Training set: current loss 0.165997  ||  Validation set: current loss 0.166015\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843  628 2638 5340 2227 3700  582 5930\n",
      "  212 2830 1791  980  911 1805  498  404 3083  451]\n",
      "Iter 45: Training set: current loss 0.165842  ||  Validation set: current loss 0.165849\n",
      "Validation:  [1539 1894 1317 3001 5677 1580 3016  628 2843 2227 5340 2638  582 5930 3700\n",
      " 2830  212  980 1791  911  498  404 1805 3226 3083]\n",
      "Iter 46: Training set: current loss 0.165650  ||  Validation set: current loss 0.165646\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      "  212  980 1791 2830  911 1805  498  404 3083  451]\n",
      "Iter 47: Training set: current loss 0.165517  ||  Validation set: current loss 0.165535\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016  628 2843 2227 5340 2638  582 3700 5930\n",
      "  212 2830 1791  980  498  911  404 1805 3226  451]\n",
      "Iter 48: Training set: current loss 0.165385  ||  Validation set: current loss 0.165399\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016 2843  628 2227 5340 2638  582 5930 3700\n",
      " 2830  212  980 1791  911  498  404 1805 3226 3083]\n",
      "Iter 49: Training set: current loss 0.165174  ||  Validation set: current loss 0.165163\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843  628 2227 5340 2638  582 5930 3700\n",
      " 2830  980  212 1791  911  498  404 1805 3226  451]\n",
      "Iter 50: Training set: current loss 0.164961  ||  Validation set: current loss 0.164947\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016 2843  628 5340 2638 2227  582 3700 5930\n",
      "  212 1791  980 2830  911 1805  498  404 3083  451]\n",
      "Iter 51: Training set: current loss 0.164793  ||  Validation set: current loss 0.164799\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016  628 2843 2227 5340 2638 5930  582 3700\n",
      " 2830 1791  212  980  498  911  404 1805 3226  451]\n",
      "Iter 52: Training set: current loss 0.164544  ||  Validation set: current loss 0.164530\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      "  212  980 2830 1791  911 1805 3083  404  498  451]\n",
      "Iter 53: Training set: current loss 0.164337  ||  Validation set: current loss 0.164362\n",
      "Validation:  [1539 1894 5677 3001 1317 1580 3016 2843  628 2227 2638 5340  582 5930 3700\n",
      " 2830  980  212 1791  911 1805  498  404 3083  451]\n",
      "Iter 54: Training set: current loss 0.164050  ||  Validation set: current loss 0.164070\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 3016 2843  628 2227 2638 5340  582 3700 5930\n",
      "  212 2830  980 1791  911 1805  498  404  451 3083]\n",
      "Iter 55: Training set: current loss 0.163822  ||  Validation set: current loss 0.163873\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843  628 5340 2227 2638  582 5930 3700\n",
      " 2830  212 1791  980  911  498  404 1805  451   78]\n",
      "Iter 56: Training set: current loss 0.163565  ||  Validation set: current loss 0.163561\n",
      "Validation:  [1539 1894 5677 1317 3001 1580 3016 2843 5340  628 2638  582 5930 2227 3700\n",
      " 1791  212  980 2830  911 1805  404   78 3083  451]\n",
      "Iter 57: Training set: current loss 0.163256  ||  Validation set: current loss 0.163242\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843  628 2227 2638 5340  582 5930 3700\n",
      " 2830  212 1791  980  911 1805  404  498  451   78]\n",
      "Iter 58: Training set: current loss 0.162958  ||  Validation set: current loss 0.162962\n",
      "Validation:  [1539 1894 5677 3001 1317 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      " 2830  980  212 1791  911 1805  404  498  451 3083]\n",
      "Iter 59: Training set: current loss 0.162581  ||  Validation set: current loss 0.162595\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843  628 5340 2227 2638 5930  582 3700\n",
      "  212 2830 1791  980  911 1805  404  451  498   78]\n",
      "Iter 60: Training set: current loss 0.162269  ||  Validation set: current loss 0.162237\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      " 2830 1791  980  212  911  404  498 1805  451   78]\n",
      "Iter 61: Training set: current loss 0.161873  ||  Validation set: current loss 0.161870\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843  628 2227 5340 2638 3700  582 5930\n",
      "  212 2830  980 1791  911 1805  404  451  498 3083]\n",
      "Iter 62: Training set: current loss 0.161535  ||  Validation set: current loss 0.161554\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843  628 5340 2638 2227  582 5930 3700\n",
      " 2830 1791  980  212  911  451 1805  404   78  498]\n",
      "Iter 63: Training set: current loss 0.161068  ||  Validation set: current loss 0.161065\n",
      "Validation:  [1539 1894 1317 3001 5677 1580 3016 2843 5340 2638  628 2227  582 5930 3700\n",
      "  212 2830  980 1791  911 1805  451  404   78 3083]\n",
      "Iter 64: Training set: current loss 0.160663  ||  Validation set: current loss 0.160670\n",
      "Validation:  [1539 1894 1317 5677 3001 1580 3016 2843 5340 2638 2227  582  628 5930 3700\n",
      "  980 2830  212 1791  911 1805  451  404   78 3083]\n",
      "Iter 65: Training set: current loss 0.160230  ||  Validation set: current loss 0.160232\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340  628 2638 2227  582 5930 3700\n",
      " 1791 2830  980  212  404  911  451   78  498 1805]\n",
      "Iter 66: Training set: current loss 0.159689  ||  Validation set: current loss 0.159684\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2227  628 2638  582 5930 3700\n",
      " 2830  980 1791  212  911  404  451 1805   78  498]\n",
      "Iter 67: Training set: current loss 0.159123  ||  Validation set: current loss 0.159151\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 2227 5930  582  628 3700\n",
      "  980 2830 1791  212  911 1805  451   78  404 3083]\n",
      "Iter 68: Training set: current loss 0.158609  ||  Validation set: current loss 0.158598\n",
      "Validation:  [1539 1894 5677 3001 1317 1580 3016 2843 2227 5340 2638  628 5930  582 3700\n",
      " 2830  212  980 1791  911  451 1805  404   78 3083]\n",
      "Iter 69: Training set: current loss 0.157998  ||  Validation set: current loss 0.157982\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 2227 5930  582  628 3700\n",
      " 2830 1791  980  212  911  451   78 1805  404 3083]\n",
      "Iter 70: Training set: current loss 0.157418  ||  Validation set: current loss 0.157399\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638 2227 5930  582 3700  628\n",
      " 1791  212 2830  980  911  451   78 1805  404 3083]\n",
      "Iter 71: Training set: current loss 0.156816  ||  Validation set: current loss 0.156799\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638 5930 2227  582 3700  628\n",
      " 1791 2830  980  212  451  911 1805   78  404 3083]\n",
      "Iter 72: Training set: current loss 0.156161  ||  Validation set: current loss 0.156126\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 2227 5930  582 3700  628\n",
      " 2830  980  212 1791  911  451   78 1805  404 4706]\n",
      "Iter 73: Training set: current loss 0.155443  ||  Validation set: current loss 0.155425\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638  582 2227 5930 3700 2830\n",
      "  628 1791  980  212  911  451 1805   78  404 4706]\n",
      "Iter 74: Training set: current loss 0.154711  ||  Validation set: current loss 0.154681\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638 2227 5930  582 3700 1791\n",
      " 2830  628  212  980  451   78  911 1805 4706  404]\n",
      "Iter 75: Training set: current loss 0.154049  ||  Validation set: current loss 0.154057\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 2227 5930  582 3700  628\n",
      " 2830  980 1791  212  911  451   78  404 1805 4811]\n",
      "Iter 76: Training set: current loss 0.153146  ||  Validation set: current loss 0.153163\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638 2227 5930  582 3700 2830\n",
      " 1791  980  628  212  451   78  911 1805  404 4706]\n",
      "Iter 77: Training set: current loss 0.152474  ||  Validation set: current loss 0.152490\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638  582 5930 2227 3700 2830\n",
      " 1791  980  212  628  451   78  911 1805 4706 4811]\n",
      "Iter 78: Training set: current loss 0.151732  ||  Validation set: current loss 0.151728\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 5340 2638 2227  582 5930 3700 2830\n",
      "  980 1791  628  212  451   78  911 1805  404 4811]\n",
      "Iter 79: Training set: current loss 0.150839  ||  Validation set: current loss 0.150871\n",
      "Validation:  [1539 1894 3001 1317 5677 1580 3016 2843 2638 5340 2227 5930  582 3700 2830\n",
      "  980  212 1791  628  451  911   78 1805 4706  404]\n",
      "Iter 80: Training set: current loss 0.150018  ||  Validation set: current loss 0.150019\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930  582 2227 1791 2830\n",
      "  980 3700  212  628  451   78  911 4811  404 4706]\n",
      "Iter 81: Training set: current loss 0.149161  ||  Validation set: current loss 0.149189\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 2227 5930  582 3700 2830\n",
      "  980 1791  212  628  451   78  911 4706 1805 4811]\n",
      "Iter 82: Training set: current loss 0.148398  ||  Validation set: current loss 0.148408\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930  582 2227 1791 2830\n",
      "  980 3700  212  628  451   78 4811  911 1805 4706]\n",
      "Iter 83: Training set: current loss 0.147600  ||  Validation set: current loss 0.147554\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930  582 2227 2830 1791\n",
      "  980 3700  212  451  628   78 4811  911 4706 1805]\n",
      "Iter 84: Training set: current loss 0.146821  ||  Validation set: current loss 0.146870\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 2227 5930  582 2830 3700\n",
      "  980 1791  212  451  628   78  911 4811  363 4706]\n",
      "Iter 85: Training set: current loss 0.145982  ||  Validation set: current loss 0.146003\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 2227 5930  582 2830 3700\n",
      " 1791  980  212  451  628   78  911 4811 4706  363]\n",
      "Iter 86: Training set: current loss 0.145266  ||  Validation set: current loss 0.145270\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 5340 2638 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78  628 4811 4706  911  363]\n",
      "Iter 87: Training set: current loss 0.144506  ||  Validation set: current loss 0.144507\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 5930 2227  582 2830 3700\n",
      " 1791  980  212  451   78  628 4811  911 4706  363]\n",
      "Iter 88: Training set: current loss 0.143805  ||  Validation set: current loss 0.143785\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930 2227  582 2830 1791\n",
      " 3700  980  212  451   78  628 4811 4706  911  363]\n",
      "Iter 89: Training set: current loss 0.143140  ||  Validation set: current loss 0.143149\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78  628 4811 4706  363  404]\n",
      "Iter 90: Training set: current loss 0.142480  ||  Validation set: current loss 0.142492\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930 2227  582 2830 3700\n",
      " 1791  980  212  451   78  628 4706  911 4811  363]\n",
      "Iter 91: Training set: current loss 0.141865  ||  Validation set: current loss 0.141883\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 2227 5930  582 2830 1791\n",
      " 3700  980  212  451   78  628 4811  911 4706  404]\n",
      "Iter 92: Training set: current loss 0.141290  ||  Validation set: current loss 0.141276\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  980  212  451   78 4811  628  363 2000  911]\n",
      "Iter 93: Training set: current loss 0.140766  ||  Validation set: current loss 0.140751\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78 4811 4706  628 2000  363]\n",
      "Iter 94: Training set: current loss 0.140190  ||  Validation set: current loss 0.140229\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930  582 2227 2830 1791\n",
      "  980  212 3700  451   78 4811 4706  628 2000  363]\n",
      "Iter 95: Training set: current loss 0.139676  ||  Validation set: current loss 0.139673\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930 2227  582 2830 1791\n",
      " 3700  980  212  451   78  628 4811 4706  911 2000]\n",
      "Iter 96: Training set: current loss 0.139189  ||  Validation set: current loss 0.139183\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78 4811  628 2000  363 4706]\n",
      "Iter 97: Training set: current loss 0.138761  ||  Validation set: current loss 0.138722\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 2227 5930  582 2830 1791\n",
      " 3700  980  212  451   78  628 4811 4706  363 2000]\n",
      "Iter 98: Training set: current loss 0.138348  ||  Validation set: current loss 0.138363\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78  628 4811  363 4706  911]\n",
      "Iter 99: Training set: current loss 0.137934  ||  Validation set: current loss 0.137929\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 5340 2638 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78 4811  363  628 4706 2000]\n",
      "Iter 100: Training set: current loss 0.137602  ||  Validation set: current loss 0.137564\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  363 4706  628]\n",
      "Iter 101: Training set: current loss 0.137216  ||  Validation set: current loss 0.137207\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 2227 5930  582 2830 1791\n",
      " 3700  980  212  451   78 4811  363 2000 4706  628]\n",
      "Iter 102: Training set: current loss 0.136848  ||  Validation set: current loss 0.136879\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811  628  363 4706 2000]\n",
      "Iter 103: Training set: current loss 0.136444  ||  Validation set: current loss 0.136462\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  628  363 4706]\n",
      "Iter 104: Training set: current loss 0.136222  ||  Validation set: current loss 0.136216\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811  363 2000  628 4706]\n",
      "Iter 105: Training set: current loss 0.135841  ||  Validation set: current loss 0.135900\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 5340 2638 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78 4811 2000 4706  363  628]\n",
      "Iter 106: Training set: current loss 0.135579  ||  Validation set: current loss 0.135583\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 3016 2843 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811  363 4706  628]\n",
      "Iter 107: Training set: current loss 0.135325  ||  Validation set: current loss 0.135298\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  363 4706  628]\n",
      "Iter 108: Training set: current loss 0.135059  ||  Validation set: current loss 0.135090\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930  582 2227 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  363 4706  628]\n",
      "Iter 109: Training set: current loss 0.134791  ||  Validation set: current loss 0.134797\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811  363 2000 4706  911]\n",
      "Iter 110: Training set: current loss 0.134603  ||  Validation set: current loss 0.134629\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811  363 2000 4706  628]\n",
      "Iter 111: Training set: current loss 0.134318  ||  Validation set: current loss 0.134331\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811  363 4706  628]\n",
      "Iter 112: Training set: current loss 0.134122  ||  Validation set: current loss 0.134083\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811  363 4706  628]\n",
      "Iter 113: Training set: current loss 0.133915  ||  Validation set: current loss 0.133912\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 3016 2843 2638 5340 2227 5930  582 2830 1791\n",
      " 3700  980  212  451   78 2000 4811  363 4706  911]\n",
      "Iter 114: Training set: current loss 0.133752  ||  Validation set: current loss 0.133766\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930  582 2227 2830 1791\n",
      "  980  451  212 3700   78 4811 2000  363 4706  628]\n",
      "Iter 115: Training set: current loss 0.133475  ||  Validation set: current loss 0.133512\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  363 4706  628]\n",
      "Iter 116: Training set: current loss 0.133255  ||  Validation set: current loss 0.133268\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  363 4706  628]\n",
      "Iter 117: Training set: current loss 0.133060  ||  Validation set: current loss 0.133099\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811 4706  363  911]\n",
      "Iter 118: Training set: current loss 0.132887  ||  Validation set: current loss 0.132907\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 5340 2638 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 4811 2000  363 4706  911]\n",
      "Iter 119: Training set: current loss 0.132670  ||  Validation set: current loss 0.132676\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811  363 4706  911]\n",
      "Iter 120: Training set: current loss 0.132456  ||  Validation set: current loss 0.132486\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811  363 4706  628]\n",
      "Iter 121: Training set: current loss 0.132330  ||  Validation set: current loss 0.132371\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 5340 2638 5930  582 2227 2830 1791\n",
      "  980  451  212 3700   78 2000 4811  363 4706 4789]\n",
      "Iter 122: Training set: current loss 0.132191  ||  Validation set: current loss 0.132182\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  212  980  451   78 2000 4811 4706  363  628]\n",
      "Iter 123: Training set: current loss 0.131921  ||  Validation set: current loss 0.131951\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  451  212   78 4811 2000  363 4706  628]\n",
      "Iter 124: Training set: current loss 0.131794  ||  Validation set: current loss 0.131792\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  980  212  451   78 4811 2000  363 4706  911]\n",
      "Iter 125: Training set: current loss 0.131619  ||  Validation set: current loss 0.131588\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  212  451   78 2000 4811  363 4706  911]\n",
      "Iter 126: Training set: current loss 0.131333  ||  Validation set: current loss 0.131369\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980  451  212 3700   78 2000 4811  363 4706  911]\n",
      "Iter 127: Training set: current loss 0.131146  ||  Validation set: current loss 0.131165\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980 3700  451  212   78 2000 4811 4706  363  911]\n",
      "Iter 128: Training set: current loss 0.130998  ||  Validation set: current loss 0.130981\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930  582 1791 2830 2227\n",
      "  980  451  212 3700   78 2000 4811  363 4706 3224]\n",
      "Iter 129: Training set: current loss 0.130750  ||  Validation set: current loss 0.130804\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980  451  212 3700   78 2000 4811 4706  363 3224]\n",
      "Iter 130: Training set: current loss 0.130599  ||  Validation set: current loss 0.130601\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  451  980  212 3700   78 2000 4811 4706  363 3224]\n",
      "Iter 131: Training set: current loss 0.130431  ||  Validation set: current loss 0.130460\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  212 3700  980  451   78 2000 4811 4706  363  911]\n",
      "Iter 132: Training set: current loss 0.130220  ||  Validation set: current loss 0.130259\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  212 3700  451  980   78 2000 4811 4706  363  911]\n",
      "Iter 133: Training set: current loss 0.130044  ||  Validation set: current loss 0.130050\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  212  451  980   78 2000 4811 4706  363 3224]\n",
      "Iter 134: Training set: current loss 0.129805  ||  Validation set: current loss 0.129794\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  980  451  212 3700   78 2000 4811 4706  363 3224]\n",
      "Iter 135: Training set: current loss 0.129641  ||  Validation set: current loss 0.129608\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  980  212  451   78 2000 4811  363 4706  911]\n",
      "Iter 136: Training set: current loss 0.129444  ||  Validation set: current loss 0.129458\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700  980   78 2000 4811 4706  363 3224]\n",
      "Iter 137: Training set: current loss 0.129291  ||  Validation set: current loss 0.129277\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 2227 5930  582 2830 1791\n",
      " 3700  212  451  980   78 2000 4811 4706  363  911]\n",
      "Iter 138: Training set: current loss 0.129027  ||  Validation set: current loss 0.129005\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  212  451  980   78 2000 4811 4706  363 3224]\n",
      "Iter 139: Training set: current loss 0.128785  ||  Validation set: current loss 0.128770\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  451  212  980 3700   78 2000 4811 4706  363 3224]\n",
      "Iter 140: Training set: current loss 0.128540  ||  Validation set: current loss 0.128547\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  451 3700  980  212   78 2000 4811 4706  363 3224]\n",
      "Iter 141: Training set: current loss 0.128393  ||  Validation set: current loss 0.128392\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  451  212  980   78 2000 4811 4706  363 3224]\n",
      "Iter 142: Training set: current loss 0.128164  ||  Validation set: current loss 0.128144\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451  212  980 3700   78 2000 4811 4706  363 3224]\n",
      "Iter 143: Training set: current loss 0.127978  ||  Validation set: current loss 0.127962\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 1791 2830\n",
      " 3700  212  451  980   78 2000 4811 4706  363  911]\n",
      "Iter 144: Training set: current loss 0.127713  ||  Validation set: current loss 0.127685\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  451  212 3700  980   78 2000 4811 4706 3224  363]\n",
      "Iter 145: Training set: current loss 0.127480  ||  Validation set: current loss 0.127532\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451 3700  212  980   78 2000 4811 4706  363 3224]\n",
      "Iter 146: Training set: current loss 0.127247  ||  Validation set: current loss 0.127231\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      " 3700  212  451  980   78 2000 4811 4706  363 3224]\n",
      "Iter 147: Training set: current loss 0.127141  ||  Validation set: current loss 0.127139\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  451  212 3700  980   78 2000 4811 4706 3224  363]\n",
      "Iter 148: Training set: current loss 0.126870  ||  Validation set: current loss 0.126888\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700  980   78 2000 4811 4706 3224  363]\n",
      "Iter 149: Training set: current loss 0.126703  ||  Validation set: current loss 0.126652\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      " 3700  212  451  980   78 2000 4811 4706 3224  363]\n",
      "Iter 150: Training set: current loss 0.126388  ||  Validation set: current loss 0.126431\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 151: Training set: current loss 0.126274  ||  Validation set: current loss 0.126277\n",
      "Validation:  [1539 1894 3001 5677 1580 2843 1317 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 152: Training set: current loss 0.125979  ||  Validation set: current loss 0.125962\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 153: Training set: current loss 0.125792  ||  Validation set: current loss 0.125765\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      " 3700  212  451  980   78 2000 4811 4706 3224  363]\n",
      "Iter 154: Training set: current loss 0.125532  ||  Validation set: current loss 0.125572\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4706 4811 3224  363]\n",
      "Iter 155: Training set: current loss 0.125363  ||  Validation set: current loss 0.125367\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 2830 1791\n",
      "  212 3700  451  980   78 2000 4811 4706 3224  363]\n",
      "Iter 156: Training set: current loss 0.125111  ||  Validation set: current loss 0.125170\n",
      "Validation:  [1539 1894 3001 5677 1317 1580 2843 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700  980   78 2000 4811 4706 3224 4789]\n",
      "Iter 157: Training set: current loss 0.124959  ||  Validation set: current loss 0.124939\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 158: Training set: current loss 0.124730  ||  Validation set: current loss 0.124728\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227 1791  582 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 159: Training set: current loss 0.124557  ||  Validation set: current loss 0.124561\n",
      "Validation:  [1539 1894 3001 5677 1580 1317 2843 2638 3016 5340 5930 2227  582 2830 1791\n",
      "  212 3700  451   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 160: Training set: current loss 0.124305  ||  Validation set: current loss 0.124336\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 3016 2638 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 161: Training set: current loss 0.124137  ||  Validation set: current loss 0.124138\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 162: Training set: current loss 0.123889  ||  Validation set: current loss 0.123906\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 163: Training set: current loss 0.123733  ||  Validation set: current loss 0.123716\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 164: Training set: current loss 0.123555  ||  Validation set: current loss 0.123579\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 165: Training set: current loss 0.123347  ||  Validation set: current loss 0.123355\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 166: Training set: current loss 0.123122  ||  Validation set: current loss 0.123164\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 167: Training set: current loss 0.123030  ||  Validation set: current loss 0.122961\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 168: Training set: current loss 0.122821  ||  Validation set: current loss 0.122802\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 169: Training set: current loss 0.122623  ||  Validation set: current loss 0.122648\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 170: Training set: current loss 0.122513  ||  Validation set: current loss 0.122527\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  451\n",
      " 2830  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 171: Training set: current loss 0.122309  ||  Validation set: current loss 0.122307\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 172: Training set: current loss 0.122247  ||  Validation set: current loss 0.122200\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791  212\n",
      " 3700 2830  451   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 173: Training set: current loss 0.122042  ||  Validation set: current loss 0.122000\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582 2830\n",
      "  451  212 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 174: Training set: current loss 0.121839  ||  Validation set: current loss 0.121838\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 175: Training set: current loss 0.121750  ||  Validation set: current loss 0.121711\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 176: Training set: current loss 0.121642  ||  Validation set: current loss 0.121591\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 177: Training set: current loss 0.121433  ||  Validation set: current loss 0.121443\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 178: Training set: current loss 0.121347  ||  Validation set: current loss 0.121384\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212 3700  451   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 179: Training set: current loss 0.121157  ||  Validation set: current loss 0.121149\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  212  451 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 180: Training set: current loss 0.121077  ||  Validation set: current loss 0.121028\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 1791 2227  582 2830\n",
      "  451  212   78 3700  980 2000 4811 4706 3224 4789]\n",
      "Iter 181: Training set: current loss 0.120836  ||  Validation set: current loss 0.120838\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      " 2830  451 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 182: Training set: current loss 0.120699  ||  Validation set: current loss 0.120743\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      "  451 2830 3700   78  980 2000 4706 3224 4811 4789]\n",
      "Iter 183: Training set: current loss 0.120575  ||  Validation set: current loss 0.120609\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 184: Training set: current loss 0.120489  ||  Validation set: current loss 0.120506\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      "  451 3700 2830   78  980 2000 4706 3224 4811 4789]\n",
      "Iter 185: Training set: current loss 0.120398  ||  Validation set: current loss 0.120437\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 2227 1791  582  451\n",
      " 2830  212 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 186: Training set: current loss 0.120220  ||  Validation set: current loss 0.120220\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      "  451 2830 3700   78  980 2000 4706 3224 4811 4789]\n",
      "Iter 187: Training set: current loss 0.120126  ||  Validation set: current loss 0.120097\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      "  451 2830 3700   78 2000  980 4706 4811 3224 4789]\n",
      "Iter 188: Training set: current loss 0.120153  ||  Validation set: current loss 0.120116\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 2638 3016 5340 5930 2227  212  582 1791\n",
      "  451 2830 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 189: Training set: current loss 0.119926  ||  Validation set: current loss 0.119915\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  451  212\n",
      "  582 2830 3700   78  980 2000 4706 3224 4811 4789]\n",
      "Iter 190: Training set: current loss 0.119779  ||  Validation set: current loss 0.119761\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227  212 1791  582\n",
      "  451 2830 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 191: Training set: current loss 0.119764  ||  Validation set: current loss 0.119744\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      "  451 2830 3700   78  980 2000 4706 4811 3224 4789]\n",
      "Iter 192: Training set: current loss 0.119562  ||  Validation set: current loss 0.119630\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78 2000  980 4811 4706 3224 4789]\n",
      "Iter 193: Training set: current loss 0.119511  ||  Validation set: current loss 0.119514\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582 2830\n",
      "  212  451 3700   78 2000  980 4706 4811 3224 4789]\n",
      "Iter 194: Training set: current loss 0.119388  ||  Validation set: current loss 0.119381\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 2227  582 1791 2830\n",
      "  451  212 3700   78  980 2000 4811 4706 3224 4789]\n",
      "Iter 195: Training set: current loss 0.119321  ||  Validation set: current loss 0.119344\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  582  212\n",
      "  451 2830 3700   78 2000  980 4706 4811 3224 4789]\n",
      "Iter 196: Training set: current loss 0.119162  ||  Validation set: current loss 0.119194\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  212  582\n",
      "  451 2830 3700   78 2000  980 4706 4811 3224 4789]\n",
      "Iter 197: Training set: current loss 0.119132  ||  Validation set: current loss 0.119122\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 1791  451 2227  582\n",
      " 2830  212   78 3700 2000  980 4706 3224 4811 4789]\n",
      "Iter 198: Training set: current loss 0.119010  ||  Validation set: current loss 0.118977\n",
      "Validation:  [1539 1894 3001 5677 2843 1580 1317 2638 3016 5340 5930 2227 1791  582 2830\n",
      "  212  451 3700   78 2000  980 4706 4811 3224 4789]\n",
      "Iter 199: Training set: current loss 0.118974  ||  Validation set: current loss 0.119002\n",
      "Validation:  [1539 1894 3001 5677 1317 2843 1580 2638 3016 5340 5930 2227  451  582 1791\n",
      "  212 2830 3700   78 2000  980 4706 3224 4811 4789]\n",
      "Iter 200: Training set: current loss 0.118893  ||  Validation set: current loss 0.118846\n",
      "Validation:  [1539 1894 3001 5677 2843 1317 1580 2638 3016 5340 5930 2227 1791  212  451\n",
      "  582 2830 3700   78 2000  980 4706 4811 3224 4789]\n",
      "Begin reconstruction phase on test dataset:\n"
     ]
    }
   ],
   "source": [
    "# Test for autoencoder\n",
    "autoencoder_1 = Autoencoder_RBM(\n",
    "       rbm_layers=[1000, 500, 100],\n",
    "       rbm_gauss_visible=True,\n",
    "       finetune_num_epochs=250,\n",
    "       finetune_loss_func='mse',\n",
    "       do_pretrain=False,\n",
    "       tied_weights=False)\n",
    "compression_1, reconstruction_1, loss_summary_1 = autoencoder_1.fit(\n",
    "    np.array(train_set_shuffle), validation_set=np.array(train_set_shuffle), test_set=np.array(train_set_shuffle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAIiCAYAAAAQI/MqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVRL0mN/k/WPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a5fe6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruction_error_1 = recons_error(np.array(train_set_shuffle), reconstruction_1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "min_bound = np.min(reconstruction_error_1) / 2.0\n",
    "max_bound = np.max(reconstruction_error_1)\n",
    "plot_range = max_bound - min_bound\n",
    "num_bins = 100\n",
    "bins = [ (min_bound + i * plot_range / num_bins) for i in range(num_bins+1)]\n",
    "freq, _, _ = plt.hist(reconstruction_error_1, bins=bins)\n",
    "\n",
    "ax = plt.axes()\n",
    "for item in index_abnormal:\n",
    "    ax.axvline(reconstruction_error_1[item], color='r', linestyle='-')\n",
    "\n",
    "ax.set_xlim([min_bound, max_bound])\n",
    "plt.xlabel(r'reconstruction error')\n",
    "plt.ylabel(r'Frequence')\n",
    "plt.title('#compression layer units = 100')\n",
    "plt.savefig('mnist_compare_100units.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: Training set: current loss 0.169777  ||  Validation set: current loss 0.169764\n",
      "Validation:  [1539 1894 1317 5677 1580 3001  628 3016 2843 2227 5340 2638  582 3700 5930\n",
      " 2830  212 1791  911  980  498 1805  404 3226 3083]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-07922dc94efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m        tied_weights=False)\n\u001b[1;32m      9\u001b[0m compression_2, reconstruction_2, loss_summary_2 = autoencoder_2.fit(\n\u001b[0;32m---> 10\u001b[0;31m     np.array(train_set_shuffle), validation_set=np.array(train_set_shuffle), test_set=np.array(train_set_shuffle))\n\u001b[0m",
      "\u001b[0;32m/Users/sq/Documents/projects/projet3A/notebooks/autoencoder_rbm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_set, validation_set, test_set, graph)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sq/Documents/projects/projet3A/notebooks/autoencoder_rbm.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, train_X, validation_X)\u001b[0m\n\u001b[1;32m    357\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                         self.keep_prob: self.finetune_dropout}\n\u001b[0;32m--> 359\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test for autoencoder\n",
    "autoencoder_2 = Autoencoder_RBM(\n",
    "       rbm_layers=[1000, 500, 10],\n",
    "       rbm_gauss_visible=True,\n",
    "       finetune_num_epochs=250,\n",
    "       finetune_loss_func='mse',\n",
    "       do_pretrain=False,\n",
    "       tied_weights=False)\n",
    "compression_2, reconstruction_2, loss_summary_2 = autoencoder_2.fit(\n",
    "    np.array(train_set_shuffle), validation_set=np.array(train_set_shuffle), test_set=np.array(train_set_shuffle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reconstruction_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-28246669d38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreconstruction_error_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecons_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set_shuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmin_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction_error_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstruction_error_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_bound\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reconstruction_2' is not defined"
     ]
    }
   ],
   "source": [
    "reconstruction_error_2 = recons_error(np.array(train_set_shuffle), reconstruction_2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "min_bound = np.min(reconstruction_error_2) / 2.0\n",
    "max_bound = np.max(reconstruction_error_2)\n",
    "plot_range = max_bound - min_bound\n",
    "num_bins = 100\n",
    "bins = [ (min_bound + i * plot_range / num_bins) for i in range(num_bins+1)]\n",
    "freq, _, _ = plt.hist(reconstruction_error_2, bins=bins)\n",
    "\n",
    "ax = plt.axes()\n",
    "for item in index_abnormal:\n",
    "    ax.axvline(reconstruction_error_2[item], color='r', linestyle='-')\n",
    "\n",
    "ax.set_xlim([min_bound, max_bound])\n",
    "plt.xlabel(r'reconstruction error')\n",
    "plt.ylabel(r'Frequence')\n",
    "plt.title('#compression layer units = 10')\n",
    "plt.savefig('mnist_compare_10units.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test for autoencoder\n",
    "autoencoder_3 = Autoencoder_RBM(\n",
    "       rbm_layers=[1000, 500, 4],\n",
    "       rbm_gauss_visible=True,\n",
    "       finetune_num_epochs=250,\n",
    "       finetune_loss_func='mse',\n",
    "       do_pretrain=False,\n",
    "       tied_weights=False)\n",
    "compression_3, reconstruction_3, loss_summary_3 = autoencoder_3.fit(\n",
    "    np.array(train_set_shuffle), validation_set=np.array(train_set_shuffle), test_set=np.array(train_set_shuffle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reconstruction_error_3 = recons_error(np.array(train_set_shuffle), reconstruction_3)\n",
    "plt.figure(figsize=(10, 6))\n",
    "min_bound = np.min(reconstruction_error_3) / 2.0\n",
    "max_bound = np.max(reconstruction_error_3)\n",
    "plot_range = max_bound - min_bound\n",
    "num_bins = 100\n",
    "bins = [ (min_bound + i * plot_range / num_bins) for i in range(num_bins+1)]\n",
    "freq, _, _ = plt.hist(reconstruction_error_3, bins=bins)\n",
    "\n",
    "ax = plt.axes()\n",
    "for item in index_abnormal:\n",
    "    ax.axvline(reconstruction_error_3[item], color='r', linestyle='-')\n",
    "\n",
    "ax.set_xlim([min_bound, max_bound])\n",
    "plt.xlabel(r'reconstruction error')\n",
    "plt.ylabel(r'Frequence')\n",
    "plt.title('#compression layer units = 4')\n",
    "plt.savefig('mnist_compare_4units.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_summary_1, 'r-', label='encoder: 784-1000-500-100')\n",
    "plt.plot(loss_summary_2, 'g-', label='encoder: 784-1000-500-10')\n",
    "plt.plot(loss_summary_3, 'b-', label='encoder: 784-1000-500-4')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_25 = [6082, 1864, 4473, 4375, 1231, 1016, 2274,  954, 2374, 3712, 4153, 4642, 5348, 3794, 5281,\n",
    "            2846, 3451, 2168, 1934,  244, 2452, 3195,  351,  186,  348]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "n_rows = 5\n",
    "n_cols = 5\n",
    "\n",
    "for i in range(n_rows * n_cols):\n",
    "    plt.subplot(n_rows, n_cols, i+1)\n",
    "    #plt.imshow(train_set_shuffle.loc[final_25[i]].reshape(28, 28),\n",
    "     #          interpolation=\"none\", cmap=\"gray_r\")\n",
    "    plt.imshow(train_set_shuffle.loc[final_25[i]].reshape(28, 28))\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_25.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number = 2\n",
    "train_set_shuffle.to_csv(('experiments/train_set_shuffle_'+str(number)+'.csv'))\n",
    "train_labels_shuffle.to_csv(('/experiments/train_labels_shuffle_1'+str(number)+'.csv'))\n",
    "pd.DataFrame(reconstruction).to_csv('/experiments/reconstruction_1'+str(number)+'.csv'))\n",
    "pd.DataFrame(compression).to_csv('/experiments/compression_1'+str(number)+'.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
