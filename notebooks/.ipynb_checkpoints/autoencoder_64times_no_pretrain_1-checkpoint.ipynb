{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from rbm import RBM\n",
    "from autoencoder_rbm import Autoencoder_RBM\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/64times_overlap.csv')\n",
    "df.drop(\"timestamp\", inplace=True, axis=1)\n",
    "#df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "df = min_max_scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: Training set: current loss 1.390221  ||  Validation set: current loss 1.390316\n",
      "Validation:  [2467 2466 2464 2495 2496 2465 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2497 2524 2601 2463  906 2522 2448  907 2455  908]\n",
      "Iter 2: Training set: current loss 1.205209  ||  Validation set: current loss 1.205270\n",
      "Validation:  [2467 2466 2495 2496 2464 2465 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2497 2524 2601 2463  906 2522  907 2448 2455  908]\n",
      "Iter 3: Training set: current loss 1.042839  ||  Validation set: current loss 1.042945\n",
      "Validation:  [2467 2466 2496 2495 2464 2465 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2497 2524 2601 2522 2463  906  907 2448  908 2455]\n",
      "Iter 4: Training set: current loss 0.904687  ||  Validation set: current loss 0.904684\n",
      "Validation:  [2467 2466 2496 2495 2465 2464 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2497 2524 2601 2522 2463  906  907 2448  908 2455]\n",
      "Iter 5: Training set: current loss 0.788547  ||  Validation set: current loss 0.788602\n",
      "Validation:  [2467 2496 2466 2495 2465 2464 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2497 2524 2601 2522 2463  906  907 2448  908 2526]\n",
      "Iter 6: Training set: current loss 0.696270  ||  Validation set: current loss 0.696306\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2497 2524 2601 2522 2463  906  907 2448  908 2526]\n",
      "Iter 7: Training set: current loss 0.621453  ||  Validation set: current loss 0.621426\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2468 2494 2493 2492 2525 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  906  907 2448 2526  908]\n",
      "Iter 8: Training set: current loss 0.563874  ||  Validation set: current loss 0.563899\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2492 2525 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  906  907 2448 2526  908]\n",
      "Iter 9: Training set: current loss 0.520761  ||  Validation set: current loss 0.520595\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2492 2525 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  906  907 2448 2526  908]\n",
      "Iter 10: Training set: current loss 0.489138  ||  Validation set: current loss 0.489172\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2492 2525 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  906  907 2448 2526  908]\n",
      "Iter 11: Training set: current loss 0.466243  ||  Validation set: current loss 0.466280\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2492 2525 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 12: Training set: current loss 0.448811  ||  Validation set: current loss 0.449061\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2492 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 13: Training set: current loss 0.435487  ||  Validation set: current loss 0.435508\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2492 2603 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 14: Training set: current loss 0.424899  ||  Validation set: current loss 0.425076\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 15: Training set: current loss 0.416164  ||  Validation set: current loss 0.416517\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 16: Training set: current loss 0.409303  ||  Validation set: current loss 0.409363\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 17: Training set: current loss 0.403370  ||  Validation set: current loss 0.403674\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 18: Training set: current loss 0.398301  ||  Validation set: current loss 0.398555\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 19: Training set: current loss 0.393966  ||  Validation set: current loss 0.394091\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 20: Training set: current loss 0.390125  ||  Validation set: current loss 0.390195\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 21: Training set: current loss 0.386307  ||  Validation set: current loss 0.386562\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 22: Training set: current loss 0.383288  ||  Validation set: current loss 0.383401\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 23: Training set: current loss 0.380339  ||  Validation set: current loss 0.380416\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 24: Training set: current loss 0.377516  ||  Validation set: current loss 0.377737\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 25: Training set: current loss 0.375112  ||  Validation set: current loss 0.375109\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2448 2526  908]\n",
      "Iter 26: Training set: current loss 0.372547  ||  Validation set: current loss 0.372670\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 27: Training set: current loss 0.370142  ||  Validation set: current loss 0.370379\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 28: Training set: current loss 0.367875  ||  Validation set: current loss 0.368198\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 29: Training set: current loss 0.365754  ||  Validation set: current loss 0.365900\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2603 2525 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 30: Training set: current loss 0.363372  ||  Validation set: current loss 0.363728\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 31: Training set: current loss 0.361140  ||  Validation set: current loss 0.361145\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2525 2603 2492 2602 2600 2523\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 32: Training set: current loss 0.358569  ||  Validation set: current loss 0.358900\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 33: Training set: current loss 0.355893  ||  Validation set: current loss 0.356204\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 34: Training set: current loss 0.353688  ||  Validation set: current loss 0.353848\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 35: Training set: current loss 0.351923  ||  Validation set: current loss 0.352076\n",
      "Validation:  [2467 2496 2495 2466 2465 2464 2494 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 36: Training set: current loss 0.350064  ||  Validation set: current loss 0.350357\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522 2463  907  906 2526 2448  908]\n",
      "Iter 37: Training set: current loss 0.348345  ||  Validation set: current loss 0.348562\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522  907 2463  906 2526 2448  908]\n",
      "Iter 38: Training set: current loss 0.346606  ||  Validation set: current loss 0.346984\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522  907 2463  906 2526 2448  908]\n",
      "Iter 39: Training set: current loss 0.344760  ||  Validation set: current loss 0.344977\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522  907 2463  906 2526  908 2448]\n",
      "Iter 40: Training set: current loss 0.343102  ||  Validation set: current loss 0.343363\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2600\n",
      " 2524 2497 2601 2522  907 2463  906 2526  908 2448]\n",
      "Iter 41: Training set: current loss 0.341485  ||  Validation set: current loss 0.341575\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907 2463  906 2526  908 2448]\n",
      "Iter 42: Training set: current loss 0.339696  ||  Validation set: current loss 0.339792\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 43: Training set: current loss 0.337815  ||  Validation set: current loss 0.338072\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 44: Training set: current loss 0.336051  ||  Validation set: current loss 0.336220\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 45: Training set: current loss 0.334181  ||  Validation set: current loss 0.334426\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 46: Training set: current loss 0.332362  ||  Validation set: current loss 0.332454\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 47: Training set: current loss 0.330371  ||  Validation set: current loss 0.330676\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 48: Training set: current loss 0.328486  ||  Validation set: current loss 0.328760\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 49: Training set: current loss 0.326556  ||  Validation set: current loss 0.326727\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 50: Training set: current loss 0.324488  ||  Validation set: current loss 0.324712\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 51: Training set: current loss 0.322569  ||  Validation set: current loss 0.322670\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 52: Training set: current loss 0.320617  ||  Validation set: current loss 0.320701\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2448]\n",
      "Iter 53: Training set: current loss 0.318466  ||  Validation set: current loss 0.318558\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908 2469]\n",
      "Iter 54: Training set: current loss 0.316453  ||  Validation set: current loss 0.316480\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2464 2468 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 55: Training set: current loss 0.314337  ||  Validation set: current loss 0.314231\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 56: Training set: current loss 0.311810  ||  Validation set: current loss 0.312008\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 57: Training set: current loss 0.309634  ||  Validation set: current loss 0.309816\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 58: Training set: current loss 0.307377  ||  Validation set: current loss 0.307740\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 59: Training set: current loss 0.305061  ||  Validation set: current loss 0.305162\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 60: Training set: current loss 0.302715  ||  Validation set: current loss 0.303104\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463 2526  908  909]\n",
      "Iter 61: Training set: current loss 0.300350  ||  Validation set: current loss 0.300514\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2523 2524\n",
      " 2600 2497 2601 2522  907  906 2463  908 2526  909]\n",
      "Iter 62: Training set: current loss 0.298068  ||  Validation set: current loss 0.298255\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2497 2601 2522  907  906 2463  908 2526  909]\n",
      "Iter 63: Training set: current loss 0.295615  ||  Validation set: current loss 0.295884\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2497 2601 2522  907  906 2463  908 2526  909]\n",
      "Iter 64: Training set: current loss 0.293193  ||  Validation set: current loss 0.293263\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2497 2601  907 2522  906 2463  908 2526  909]\n",
      "Iter 65: Training set: current loss 0.290664  ||  Validation set: current loss 0.290806\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2497 2601  907 2522  906 2463  908 2526  909]\n",
      "Iter 66: Training set: current loss 0.288053  ||  Validation set: current loss 0.288198\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 67: Training set: current loss 0.285567  ||  Validation set: current loss 0.285642\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 68: Training set: current loss 0.282957  ||  Validation set: current loss 0.283170\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 69: Training set: current loss 0.280328  ||  Validation set: current loss 0.280570\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 70: Training set: current loss 0.277674  ||  Validation set: current loss 0.277922\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 71: Training set: current loss 0.274886  ||  Validation set: current loss 0.275224\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 72: Training set: current loss 0.272234  ||  Validation set: current loss 0.272500\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 73: Training set: current loss 0.269595  ||  Validation set: current loss 0.269759\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 74: Training set: current loss 0.266930  ||  Validation set: current loss 0.267108\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 75: Training set: current loss 0.264037  ||  Validation set: current loss 0.264318\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 76: Training set: current loss 0.261126  ||  Validation set: current loss 0.261452\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 77: Training set: current loss 0.258466  ||  Validation set: current loss 0.258653\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907 2522  906 2463  908 2526  909]\n",
      "Iter 78: Training set: current loss 0.255539  ||  Validation set: current loss 0.255763\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522 2463  908 2526  909]\n",
      "Iter 79: Training set: current loss 0.252958  ||  Validation set: current loss 0.253016\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 80: Training set: current loss 0.250070  ||  Validation set: current loss 0.250302\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 81: Training set: current loss 0.247211  ||  Validation set: current loss 0.247440\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 82: Training set: current loss 0.244452  ||  Validation set: current loss 0.244632\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 83: Training set: current loss 0.241553  ||  Validation set: current loss 0.241671\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 84: Training set: current loss 0.238663  ||  Validation set: current loss 0.238744\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2600 2601 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 85: Training set: current loss 0.235853  ||  Validation set: current loss 0.236081\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 86: Training set: current loss 0.232892  ||  Validation set: current loss 0.233156\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 87: Training set: current loss 0.230015  ||  Validation set: current loss 0.230182\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 88: Training set: current loss 0.227164  ||  Validation set: current loss 0.227287\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2492 2602 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 89: Training set: current loss 0.224558  ||  Validation set: current loss 0.224463\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 90: Training set: current loss 0.221559  ||  Validation set: current loss 0.221716\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 91: Training set: current loss 0.218973  ||  Validation set: current loss 0.218871\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2464 2493 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 92: Training set: current loss 0.216235  ||  Validation set: current loss 0.216310\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 93: Training set: current loss 0.213555  ||  Validation set: current loss 0.213776\n",
      "Validation:  [2467 2496 2495 2466 2465 2494 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2463 2526  909]\n",
      "Iter 94: Training set: current loss 0.210980  ||  Validation set: current loss 0.211080\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2526 2463  909]\n",
      "Iter 95: Training set: current loss 0.208452  ||  Validation set: current loss 0.208605\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2526 2463  909]\n",
      "Iter 96: Training set: current loss 0.205948  ||  Validation set: current loss 0.206172\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2526 2463  909]\n",
      "Iter 97: Training set: current loss 0.203430  ||  Validation set: current loss 0.203678\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2526  909 2463]\n",
      "Iter 98: Training set: current loss 0.201055  ||  Validation set: current loss 0.201234\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2526  909 2463]\n",
      "Iter 99: Training set: current loss 0.198690  ||  Validation set: current loss 0.199019\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908 2526  909 2463]\n",
      "Iter 100: Training set: current loss 0.196523  ||  Validation set: current loss 0.196842\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 101: Training set: current loss 0.194320  ||  Validation set: current loss 0.194542\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 102: Training set: current loss 0.192255  ||  Validation set: current loss 0.192570\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 103: Training set: current loss 0.190332  ||  Validation set: current loss 0.190550\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 104: Training set: current loss 0.188222  ||  Validation set: current loss 0.188639\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 105: Training set: current loss 0.186278  ||  Validation set: current loss 0.186864\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 106: Training set: current loss 0.184685  ||  Validation set: current loss 0.184918\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 107: Training set: current loss 0.182880  ||  Validation set: current loss 0.183257\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 108: Training set: current loss 0.181178  ||  Validation set: current loss 0.181615\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 109: Training set: current loss 0.179661  ||  Validation set: current loss 0.180092\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 110: Training set: current loss 0.178351  ||  Validation set: current loss 0.178540\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 111: Training set: current loss 0.176924  ||  Validation set: current loss 0.177160\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 112: Training set: current loss 0.175702  ||  Validation set: current loss 0.175906\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2492 2524 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 113: Training set: current loss 0.174309  ||  Validation set: current loss 0.174626\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 114: Training set: current loss 0.173163  ||  Validation set: current loss 0.173384\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 115: Training set: current loss 0.172133  ||  Validation set: current loss 0.172364\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 116: Training set: current loss 0.170951  ||  Validation set: current loss 0.171297\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 117: Training set: current loss 0.170050  ||  Validation set: current loss 0.170246\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 118: Training set: current loss 0.169035  ||  Validation set: current loss 0.169351\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 119: Training set: current loss 0.168235  ||  Validation set: current loss 0.168445\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 120: Training set: current loss 0.167408  ||  Validation set: current loss 0.167629\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 121: Training set: current loss 0.166669  ||  Validation set: current loss 0.166909\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 122: Training set: current loss 0.166010  ||  Validation set: current loss 0.166213\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 123: Training set: current loss 0.165358  ||  Validation set: current loss 0.165558\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 124: Training set: current loss 0.164776  ||  Validation set: current loss 0.164976\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 125: Training set: current loss 0.164206  ||  Validation set: current loss 0.164427\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 126: Training set: current loss 0.163678  ||  Validation set: current loss 0.163874\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 127: Training set: current loss 0.163273  ||  Validation set: current loss 0.163402\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 128: Training set: current loss 0.162754  ||  Validation set: current loss 0.162979\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 129: Training set: current loss 0.162398  ||  Validation set: current loss 0.162584\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 130: Training set: current loss 0.161975  ||  Validation set: current loss 0.162167\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 131: Training set: current loss 0.161584  ||  Validation set: current loss 0.161812\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 132: Training set: current loss 0.161310  ||  Validation set: current loss 0.161531\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 133: Training set: current loss 0.160991  ||  Validation set: current loss 0.161254\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 134: Training set: current loss 0.160712  ||  Validation set: current loss 0.161016\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 135: Training set: current loss 0.160563  ||  Validation set: current loss 0.160777\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 136: Training set: current loss 0.160209  ||  Validation set: current loss 0.160512\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 137: Training set: current loss 0.160119  ||  Validation set: current loss 0.160348\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 138: Training set: current loss 0.159922  ||  Validation set: current loss 0.160169\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 139: Training set: current loss 0.159804  ||  Validation set: current loss 0.159975\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 140: Training set: current loss 0.159620  ||  Validation set: current loss 0.159855\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 141: Training set: current loss 0.159544  ||  Validation set: current loss 0.159707\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 142: Training set: current loss 0.159458  ||  Validation set: current loss 0.159581\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 143: Training set: current loss 0.159319  ||  Validation set: current loss 0.159494\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n",
      "Iter 144: Training set: current loss 0.159196  ||  Validation set: current loss 0.159390\n",
      "Validation:  [2467 2496 2495 2466 2494 2465 2468 2493 2464 2603 2525 2602 2524 2492 2523\n",
      " 2601 2600 2497  907  906 2522  908  909 2526 2463]\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder_RBM(rbm_layers=[1000, 500, 100],\n",
    "                              rbm_gauss_visible=True,\n",
    "                              finetune_num_epochs=300,\n",
    "                              do_pretrain=False,\n",
    "                              finetune_loss_func='mse')\n",
    "\n",
    "\n",
    "compres, recons, loss_summary = autoencoder.fit(np.array(df), validation_set=np.array(df), test_set = np.array(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recons_error(input_set, recons):\n",
    "    dif = input_set - recons\n",
    "    dif = np.power(dif, 2)\n",
    "    return np.mean(dif, axis=1)\n",
    "\n",
    "reconstruction_error = recons_error(np.array(train_set_shuffle), recons)\n",
    "plt.figure(figsize=(10, 6))\n",
    "min_bound = np.min(reconstruction_error_1) / 2.0\n",
    "max_bound = np.max(reconstruction_error_1)\n",
    "plot_range = max_bound - min_bound\n",
    "num_bins = 100\n",
    "bins = [ (min_bound + i * plot_range / num_bins) for i in range(num_bins+1)]\n",
    "freq, _, _ = plt.hist(reconstruction_error_1, bins=bins)\n",
    "\n",
    "ax = plt.axes()\n",
    "for item in index_abnormal:\n",
    "    ax.axvline(reconstruction_error_1[item], color='r', linestyle='-')\n",
    "\n",
    "ax.set_xlim([min_bound, max_bound])\n",
    "plt.xlabel(r'reconstruction error')\n",
    "plt.ylabel(r'Frequence')\n",
    "plt.title('#compression layer units = 100')\n",
    "plt.savefig('hdp_1000_500_100.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
